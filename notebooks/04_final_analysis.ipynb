{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e5950",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Load All Data\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load all processed data\n",
    "merged_data = pd.read_csv('../data/processed/merged_data.csv')\n",
    "print(f\"Loaded merged data: {merged_data.shape}\")\n",
    "\n",
    "# Cell 2: Advanced Trader Segmentation\n",
    "print(\"=== ADVANCED TRADER SEGMENTATION ===\")\n",
    "\n",
    "# Calculate comprehensive trader metrics\n",
    "trader_metrics = merged_data.groupby('account').agg({\n",
    "    'closedPnL': ['sum', 'mean', 'std', 'count', 'min', 'max'],\n",
    "    'size': ['mean', 'sum', 'std'],\n",
    "    'leverage': ['mean', 'std'],\n",
    "    'is_profitable': ['mean', 'sum'],\n",
    "    'sentiment_score': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "trader_metrics.columns = ['_'.join(col).strip() for col in trader_metrics.columns]\n",
    "trader_metrics = trader_metrics.reset_index()\n",
    "\n",
    "# Calculate additional metrics\n",
    "trader_metrics['total_pnl'] = trader_metrics['closedPnL_sum']\n",
    "trader_metrics['avg_pnl'] = trader_metrics['closedPnL_mean']\n",
    "trader_metrics['win_rate'] = trader_metrics['is_profitable_mean']\n",
    "trader_metrics['trade_count'] = trader_metrics['closedPnL_count']\n",
    "trader_metrics['pnl_volatility'] = trader_metrics['closedPnL_std']\n",
    "trader_metrics['sharpe_ratio'] = trader_metrics['avg_pnl'] / trader_metrics['pnl_volatility']\n",
    "trader_metrics['sharpe_ratio'] = trader_metrics['sharpe_ratio'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"Analyzed {len(trader_metrics)} unique traders\")\n",
    "print(\"\\nTrader metrics summary:\")\n",
    "print(trader_metrics[['total_pnl', 'win_rate', 'trade_count', 'sharpe_ratio']].describe())\n",
    "\n",
    "# Cell 3: Trader Clustering Analysis\n",
    "print(\"=== TRADER CLUSTERING ANALYSIS ===\")\n",
    "\n",
    "# Select features for clustering\n",
    "clustering_features = ['total_pnl', 'win_rate', 'trade_count', 'avg_pnl', 'pnl_volatility']\n",
    "clustering_data = trader_metrics[clustering_features].fillna(0)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(clustering_data)\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Use k=4 clusters (adjust based on elbow curve)\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "trader_metrics['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Analyze clusters\n",
    "print(f\"\\nCluster Analysis (k={optimal_k}):\")\n",
    "cluster_summary = trader_metrics.groupby('cluster')[clustering_features].mean().round(4)\n",
    "print(cluster_summary)\n",
    "\n",
    "# Visualize clusters\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Cluster distribution\n",
    "cluster_counts = trader_metrics['cluster'].value_counts().sort_index()\n",
    "axes[0,0].bar(cluster_counts.index, cluster_counts.values, color='skyblue')\n",
    "axes[0,0].set_title('Trader Distribution by Cluster')\n",
    "axes[0,0].set_xlabel('Cluster')\n",
    "axes[0,0].set_ylabel('Number of Traders')\n",
    "\n",
    "# PnL vs Win Rate by cluster\n",
    "scatter = axes[0,1].scatter(trader_metrics['win_rate'], trader_metrics['total_pnl'], \n",
    "                           c=trader_metrics['cluster'], cmap='viridis', alpha=0.7)\n",
    "axes[0,1].set_xlabel('Win Rate')\n",
    "axes[0,1].set_ylabel('Total PnL')\n",
    "axes[0,1].set_title('Traders by Win Rate vs Total PnL')\n",
    "plt.colorbar(scatter, ax=axes[0,1])\n",
    "\n",
    "# Trade Count vs PnL by cluster\n",
    "scatter2 = axes[1,0].scatter(trader_metrics['trade_count'], trader_metrics['total_pnl'], \n",
    "                            c=trader_metrics['cluster'], cmap='viridis', alpha=0.7)\n",
    "axes[1,0].set_xlabel('Trade Count')\n",
    "axes[1,0].set_ylabel('Total PnL')\n",
    "axes[1,0].set_title('Traders by Trade Count vs Total PnL')\n",
    "plt.colorbar(scatter2, ax=axes[1,0])\n",
    "\n",
    "# Cluster characteristics heatmap\n",
    "cluster_chars = trader_metrics.groupby('cluster')[clustering_features].mean()\n",
    "sns.heatmap(cluster_chars.T, annot=True, cmap='RdYlBu_r', ax=axes[1,1])\n",
    "axes[1,1].set_title('Cluster Characteristics Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 4: Predictive Modeling\n",
    "print(\"=== PREDICTIVE MODELING ===\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "modeling_data = merged_data.dropna(subset=['closedPnL', 'size', 'leverage', 'sentiment_score'])\n",
    "\n",
    "# Feature engineering for modeling\n",
    "features = ['size', 'leverage', 'sentiment_score']\n",
    "if 'hour' in modeling_data.columns:\n",
    "    features.append('hour')\n",
    "if 'day_of_week' in modeling_data.columns:\n",
    "    features.append('day_of_week')\n",
    "\n",
    "X = modeling_data[features]\n",
    "y = modeling_data['closedPnL']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for PnL Prediction')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Cell 5: Sentiment Impact Deep Dive\n",
    "print(\"=== SENTIMENT IMPACT DEEP DIVE ===\")\n",
    "\n",
    "# Analyze sentiment impact by trader cluster\n",
    "sentiment_cluster_analysis = merged_data.merge(\n",
    "    trader_metrics[['account', 'cluster']], \n",
    "    on='account', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "cluster_sentiment_performance = sentiment_cluster_analysis.groupby(['cluster', 'Classification']).agg({\n",
    "    'closedPnL': ['mean', 'std', 'count'],\n",
    "    'is_profitable': 'mean',\n",
    "    'size': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"Performance by Cluster and Sentiment:\")\n",
    "print(cluster_sentiment_performance)\n",
    "\n",
    "# Visualize sentiment impact by cluster\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# PnL by sentiment and cluster\n",
    "pivot_pnl = sentiment_cluster_analysis.pivot_table(\n",
    "    values='closedPnL', \n",
    "    index='cluster', \n",
    "    columns='Classification', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "sns.heatmap(pivot_pnl, annot=True, cmap='RdYlGn', ax=axes[0,0])\n",
    "axes[0,0].set_title('Average PnL by Cluster and Sentiment')\n",
    "\n",
    "# Win rate by sentiment and cluster\n",
    "pivot_winrate = sentiment_cluster_analysis.pivot_table(\n",
    "    values='is_profitable', \n",
    "    index='cluster', \n",
    "    columns='Classification', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "sns.heatmap(pivot_winrate, annot=True, cmap='RdYlGn', ax=axes[0,1])\n",
    "axes[0,1].set_title('Win Rate by Cluster and Sentiment')\n",
    "\n",
    "# Box plot of PnL by cluster for each sentiment\n",
    "for i, sentiment in enumerate(['Fear', 'Greed']):\n",
    "    sentiment_data = sentiment_cluster_analysis[sentiment_cluster_analysis['Classification'] == sentiment]\n",
    "    if not sentiment_data.empty:\n",
    "        sns.boxplot(data=sentiment_data, x='cluster', y='closedPnL', ax=axes[1,i])\n",
    "        axes[1,i].set_title(f'PnL Distribution by Cluster ({sentiment})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 6: Market Regime Analysis\n",
    "print(\"=== MARKET REGIME ANALYSIS ===\")\n",
    "\n",
    "# Analyze performance in different market conditions\n",
    "if 'date' in merged_data.columns:\n",
    "    merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
    "    \n",
    "    # Calculate rolling metrics\n",
    "    daily_metrics = merged_data.groupby('date').agg({\n",
    "        'closedPnL': ['sum', 'mean', 'std'],\n",
    "        'size': 'sum',\n",
    "        'Classification': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'\n",
    "    })\n",
    "    \n",
    "    daily_metrics.columns = ['daily_pnl_sum', 'daily_pnl_mean', 'daily_pnl_std', 'daily_volume', 'dominant_sentiment']\n",
    "    \n",
    "    # Calculate rolling volatility\n",
    "    daily_metrics['volatility_7d'] = daily_metrics['daily_pnl_std'].rolling(7).mean()\n",
    "    daily_metrics['pnl_trend_7d'] = daily_metrics['daily_pnl_sum'].rolling(7).mean()\n",
    "    \n",
    "    # Define market regimes\n",
    "    vol_median = daily_metrics['volatility_7d'].median()\n",
    "    trend_median = daily_metrics['pnl_trend_7d'].median()\n",
    "    \n",
    "    conditions = [\n",
    "        (daily_metrics['volatility_7d'] <= vol_median) & (daily_metrics['pnl_trend_7d'] >= trend_median),\n",
    "        (daily_metrics['volatility_7d'] <= vol_median) & (daily_metrics['pnl_trend_7d'] < trend_median),\n",
    "        (daily_metrics['volatility_7d'] > vol_median) & (daily_metrics['pnl_trend_7d'] >= trend_median),\n",
    "        (daily_metrics['volatility_7d'] > vol_median) & (daily_metrics['pnl_trend_7d'] < trend_median)\n",
    "    ]\n",
    "    \n",
    "    choices = ['Low_Vol_Positive', 'Low_Vol_Negative', 'High_Vol_Positive', 'High_Vol_Negative']\n",
    "    daily_metrics['market_regime'] = np.select(conditions, choices, default='Undefined')\n",
    "    \n",
    "    # Merge back with main data\n",
    "    merged_data_regime = merged_data.merge(\n",
    "        daily_metrics[['market_regime']].reset_index(),\n",
    "        on='date',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Analyze performance by market regime\n",
    "    regime_performance = merged_data_regime.groupby('market_regime').agg({\n",
    "        'closedPnL': ['count', 'mean', 'std'],\n",
    "        'is_profitable': 'mean',\n",
    "        'size': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"Performance by Market Regime:\")\n",
    "    print(regime_performance)\n",
    "    \n",
    "    # Visualize market regimes\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    regime_colors = {'Low_Vol_Positive': 'green', 'Low_Vol_Negative': 'lightcoral', \n",
    "                    'High_Vol_Positive': 'darkgreen', 'High_Vol_Negative': 'red'}\n",
    "    \n",
    "    for regime in daily_metrics['market_regime'].unique():\n",
    "        if regime != 'Undefined':\n",
    "            regime_data = daily_metrics[daily_metrics['market_regime'] == regime]\n",
    "            plt.scatter(regime_data.index, regime_data['daily_pnl_sum'], \n",
    "                       label=regime, color=regime_colors.get(regime, 'gray'), alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Daily PnL Sum')\n",
    "    plt.title('Market Regimes and Daily PnL')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Cell 7: Risk-Adjusted Performance Analysis\n",
    "print(\"=== RISK-ADJUSTED PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Calculate risk-adjusted metrics for each trader\n",
    "trader_risk_metrics = merged_data.groupby('account').agg({\n",
    "    'closedPnL': ['mean', 'std', 'sum', 'count'],\n",
    "    'size': 'mean',\n",
    "    'leverage': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "trader_risk_metrics.columns = ['avg_pnl', 'pnl_std', 'total_pnl', 'trade_count', 'avg_size', 'avg_leverage']\n",
    "trader_risk_metrics = trader_risk_metrics.reset_index()\n",
    "\n",
    "# Calculate additional risk metrics\n",
    "trader_risk_metrics['sharpe_ratio'] = trader_risk_metrics['avg_pnl'] / trader_risk_metrics['pnl_std']\n",
    "trader_risk_metrics['sharpe_ratio'] = trader_risk_metrics['sharpe_ratio'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Calculate downside deviation\n",
    "downside_returns = merged_data[merged_data['closedPnL'] < 0].groupby('account')['closedPnL'].std()\n",
    "trader_risk_metrics = trader_risk_metrics.merge(\n",
    "    downside_returns.reset_index().rename(columns={'closedPnL': 'downside_std'}),\n",
    "    on='account',\n",
    "    how='left'\n",
    ")\n",
    "trader_risk_metrics['downside_std'] = trader_risk_metrics['downside_std'].fillna(0)\n",
    "trader_risk_metrics['sortino_ratio'] = trader_risk_metrics['avg_pnl'] / trader_risk_metrics['downside_std']\n",
    "trader_risk_metrics['sortino_ratio'] = trader_risk_metrics['sortino_ratio'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Maximum drawdown calculation (simplified)\n",
    "def calculate_max_drawdown(account_data):\n",
    "    cumulative = account_data['closedPnL'].cumsum()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    return drawdown.min() if len(drawdown) > 0 else 0\n",
    "\n",
    "max_drawdowns = merged_data.groupby('account').apply(calculate_max_drawdown)\n",
    "trader_risk_metrics = trader_risk_metrics.merge(\n",
    "    max_drawdowns.reset_index().rename(columns={0: 'max_drawdown'}),\n",
    "    on='account',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Risk-Adjusted Performance Metrics:\")\n",
    "print(trader_risk_metrics[['account', 'sharpe_ratio', 'sortino_ratio', 'max_drawdown']].head(10))\n",
    "\n",
    "# Risk-return scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(trader_risk_metrics['pnl_std'], trader_risk_metrics['avg_pnl'], \n",
    "                     c=trader_risk_metrics['sharpe_ratio'], cmap='RdYlGn', alpha=0.7)\n",
    "plt.colorbar(scatter, label='Sharpe Ratio')\n",
    "plt.xlabel('PnL Standard Deviation (Risk)')\n",
    "plt.ylabel('Average PnL (Return)')\n",
    "plt.title('Risk-Return Profile of Traders')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Cell 8: Advanced Pattern Recognition\n",
    "print(\"=== ADVANCED PATTERN RECOGNITION ===\")\n",
    "\n",
    "# Identify trading patterns\n",
    "# Pattern 1: Sentiment contrarians (perform better when sentiment is opposite)\n",
    "trader_sentiment_performance = merged_data.groupby(['account', 'Classification'])['closedPnL'].mean().unstack(fill_value=0)\n",
    "\n",
    "if 'Fear' in trader_sentiment_performance.columns and 'Greed' in trader_sentiment_performance.columns:\n",
    "    # Calculate sentiment preference\n",
    "    trader_sentiment_performance['fear_preference'] = (\n",
    "        trader_sentiment_performance['Fear'] - trader_sentiment_performance['Greed']\n",
    "    )\n",
    "    \n",
    "    # Identify contrarians (perform better during fear)\n",
    "    contrarians = trader_sentiment_performance[trader_sentiment_performance['fear_preference'] > 0].index\n",
    "    momentum_traders = trader_sentiment_performance[trader_sentiment_performance['fear_preference'] < 0].index\n",
    "    \n",
    "    print(f\"Contrarian traders (better in Fear): {len(contrarians)}\")\n",
    "    print(f\"Momentum traders (better in Greed): {len(momentum_traders)}\")\n",
    "    \n",
    "    # Analyze contrarian vs momentum trader characteristics\n",
    "    trader_types = pd.DataFrame({\n",
    "        'account': list(contrarians) + list(momentum_traders),\n",
    "        'type': ['Contrarian'] * len(contrarians) + ['Momentum'] * len(momentum_traders)\n",
    "    })\n",
    "    \n",
    "    trader_type_analysis = merged_data.merge(trader_types, on='account', how='inner')\n",
    "    \n",
    "    type_performance = trader_type_analysis.groupby('type').agg({\n",
    "        'closedPnL': ['mean', 'std', 'sum'],\n",
    "        'leverage': 'mean',\n",
    "        'size': 'mean',\n",
    "        'is_profitable': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"\\nTrader Type Performance:\")\n",
    "    print(type_performance)\n",
    "\n",
    "# Pattern 2: High-frequency vs Low-frequency traders\n",
    "trade_frequency = merged_data.groupby('account').size()\n",
    "freq_quartiles = trade_frequency.quantile([0.25, 0.75])\n",
    "\n",
    "high_freq_traders = trade_frequency[trade_frequency >= freq_quartiles[0.75]].index\n",
    "low_freq_traders = trade_frequency[trade_frequency <= freq_quartiles[0.25]].index\n",
    "\n",
    "freq_analysis = merged_data[merged_data['account'].isin(list(high_freq_traders) + list(low_freq_traders))].copy()\n",
    "freq_analysis['frequency_type'] = freq_analysis['account'].apply(\n",
    "    lambda x: 'High_Frequency' if x in high_freq_traders else 'Low_Frequency'\n",
    ")\n",
    "\n",
    "freq_performance = freq_analysis.groupby('frequency_type').agg({\n",
    "    'closedPnL': ['mean', 'std', 'sum'],\n",
    "    'leverage': 'mean',\n",
    "    'is_profitable': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(f\"\\nFrequency Analysis:\")\n",
    "print(f\"High-frequency traders: {len(high_freq_traders)}\")\n",
    "print(f\"Low-frequency traders: {len(low_freq_traders)}\")\n",
    "print(freq_performance)\n",
    "\n",
    "# Cell 9: Portfolio-Level Analysis\n",
    "print(\"=== PORTFOLIO-LEVEL ANALYSIS ===\")\n",
    "\n",
    "# Simulate a portfolio based on different strategies\n",
    "if 'date' in merged_data.columns:\n",
    "    # Strategy 1: Follow top performers\n",
    "    top_performers = trader_metrics.nlargest(10, 'total_pnl')['account'].tolist()\n",
    "    \n",
    "    # Strategy 2: Follow contrarians during fear\n",
    "    if len(contrarians) > 0:\n",
    "        top_contrarians = trader_sentiment_performance.loc[contrarians].nlargest(5, 'fear_preference').index.tolist()\n",
    "    else:\n",
    "        top_contrarians = []\n",
    "    \n",
    "    # Calculate portfolio performance\n",
    "    portfolio_strategies = {\n",
    "        'Top_Performers': top_performers,\n",
    "        'Contrarians': top_contrarians if top_contrarians else top_performers[:5]\n",
    "    }\n",
    "    \n",
    "    portfolio_results = {}\n",
    "    \n",
    "    for strategy, traders in portfolio_strategies.items():\n",
    "        strategy_data = merged_data[merged_data['account'].isin(traders)]\n",
    "        daily_portfolio = strategy_data.groupby('date')['closedPnL'].sum()\n",
    "        \n",
    "        portfolio_results[strategy] = {\n",
    "            'total_return': daily_portfolio.sum(),\n",
    "            'daily_volatility': daily_portfolio.std(),\n",
    "            'sharpe_ratio': daily_portfolio.mean() / daily_portfolio.std() if daily_portfolio.std() > 0 else 0,\n",
    "            'max_daily_loss': daily_portfolio.min(),\n",
    "            'max_daily_gain': daily_portfolio.max()\n",
    "        }\n",
    "    \n",
    "    print(\"Portfolio Strategy Performance:\")\n",
    "    portfolio_df = pd.DataFrame(portfolio_results).T\n",
    "    print(portfolio_df)\n",
    "    \n",
    "    # Plot portfolio performance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for strategy, traders in portfolio_strategies.items():\n",
    "        strategy_data = merged_data[merged_data['account'].isin(traders)]\n",
    "        daily_portfolio = strategy_data.groupby('date')['closedPnL'].sum().cumsum()\n",
    "        plt.plot(daily_portfolio.index, daily_portfolio.values, label=strategy, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative PnL')\n",
    "    plt.title('Portfolio Strategy Performance Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Cell 10: Final Insights and Recommendations\n",
    "print(\"=== FINAL INSIGHTS AND RECOMMENDATIONS ===\")\n",
    "\n",
    "# Generate comprehensive insights\n",
    "insights = {\n",
    "    'trader_segmentation': {\n",
    "        'total_traders': len(trader_metrics),\n",
    "        'profitable_traders': len(trader_metrics[trader_metrics['total_pnl'] > 0]),\n",
    "        'top_10_pct_pnl': trader_metrics['total_pnl'].quantile(0.9),\n",
    "        'avg_trades_per_trader': trader_metrics['trade_count'].mean()\n",
    "    },\n",
    "    'sentiment_impact': {\n",
    "        'fear_avg_pnl': merged_data[merged_data['Classification'] == 'Fear']['closedPnL'].mean(),\n",
    "        'greed_avg_pnl': merged_data[merged_data['Classification'] == 'Greed']['closedPnL'].mean(),\n",
    "        'sentiment_correlation': merged_data[['closedPnL', 'sentiment_score']].corr().iloc[0,1]\n",
    "    },\n",
    "    'risk_patterns': {\n",
    "        'avg_sharpe_ratio': trader_risk_metrics['sharpe_ratio'].mean(),\n",
    "        'high_sharpe_threshold': trader_risk_metrics['sharpe_ratio'].quantile(0.8),\n",
    "        'avg_max_drawdown': trader_risk_metrics['max_drawdown'].mean()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(f\"1. {insights['trader_segmentation']['profitable_traders']}/{insights['trader_segmentation']['total_traders']} traders were profitable\")\n",
    "print(f\"2. Top 10% threshold PnL: {insights['trader_segmentation']['top_10_pct_pnl']:.2f}\")\n",
    "print(f\"3. Average PnL during Fear: {insights['sentiment_impact']['fear_avg_pnl']:.4f}\")\n",
    "print(f\"4. Average PnL during Greed: {insights['sentiment_impact']['greed_avg_pnl']:.4f}\")\n",
    "print(f\"5. PnL-Sentiment correlation: {insights['sentiment_impact']['sentiment_correlation']:.4f}\")\n",
    "print(f\"6. Average Sharpe ratio: {insights['risk_patterns']['avg_sharpe_ratio']:.4f}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nRECOMMENDATIONS:\")\n",
    "print(\"1. Focus on traders in the top-performing clusters for strategy insights\")\n",
    "print(\"2. Consider sentiment as a factor in trading strategies\")\n",
    "print(\"3. Implement risk management based on identified drawdown patterns\")\n",
    "print(\"4. Diversify across different trader types (contrarian vs momentum)\")\n",
    "print(\"5. Monitor market regime changes for strategy adaptation\")\n",
    "\n",
    "# Save all results\n",
    "final_results = {\n",
    "    'trader_metrics': trader_metrics,\n",
    "    'cluster_analysis': cluster_summary,\n",
    "    'model_performance': {'mse': mse, 'r2': r2, 'feature_importance': feature_importance},\n",
    "    'insights': insights,\n",
    "    'portfolio_results': portfolio_results if 'portfolio_results' in locals() else None\n",
    "}\n",
    "\n",
    "# Save to pickle file\n",
    "with open('../data/outputs/final_analysis_results.pkl', 'wb') as f:\n",
    "    pickle.dump(final_results, f)\n",
    "\n",
    "# Save key dataframes\n",
    "trader_metrics.to_csv('../data/outputs/final_trader_metrics.csv', index=False)\n",
    "if 'trader_risk_metrics' in locals():\n",
    "    trader_risk_metrics.to_csv('../data/outputs/trader_risk_metrics.csv', index=False)\n",
    "\n",
    "print(\"\\n Final analysis complete! All results saved to outputs folder.\")\n",
    "print(\" Check the following files:\")\n",
    "print(\"- final_analysis_results.pkl (comprehensive results)\")\n",
    "print(\"- final_trader_metrics.csv (trader performance metrics)\")\n",
    "print(\"- trader_risk_metrics.csv (risk-adjusted metrics)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
